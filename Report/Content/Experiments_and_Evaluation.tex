\section{Experiments \& Evaluation}

This section will benchmark the performance of Spiral against the coulouring and PBC
datasets of our study.

\subsection{Experimental Setup}

\textbf{Spiral Parameters} \hspace{0.3cm} We run our server and client executables over the same set
of parameters. These parameters are selected through the automatic parameter
selection\cite{1}, and is determined before the server and client are executed.

\textbf{Hardware} \hspace{0.3cm} Evaluation of Spiral is performed over a \texttt{M5zn} AWS
instance with 32 vCPUs and 128GiB of memory. \texttt{AVX512F} and \texttt{AVX2}
support was enabled, and the instance was running on Ubuntu 20.04. We used \texttt{Clang
12} and compiled with \texttt{O3} optimisations.

\textbf{Trials} \hspace{0.3cm} Trials are ran over a pre-defiend indices file generated by
 the colouring and PBC algorithms. These set of indices are a realistic depiction of how
 hashes will be queried in a realistic implementation.

\textbf{Measurements} \hspace{0.3cm} Time measurements are taken using the
\texttt{std::chrono::high\_resolution\_clock}. The average, minimum and maximum values are
recorded for each metric. These averages are taken over the number of indices specified in
a single indices file.

\subsection{Metrics}

We use the following metrics to evaluate the performance of Spiral:

\itemize
\item \textbf{Database-Dependant Compuation} The time taken by the server to
process the query against the database and produce a result.
\item \textbf{Database Generation} The time required to load and encoded a database of
size $N$ into memory on the server.
\item \textbf{Query Generation} The time taken to generate a client-side query.
\item \textbf{Response Extraction} The time taken to decode and extract the requested hash
from the server response on the client.
\item \textbf{Rate} The ratio of the response size to the size of the retrieved record.
The rate stands to measure the overehead in the server-client communication.
\item \textbf{Query Size} The size of the encoded query sent by the client to the server.
\item \textbf{Response Size} The size of the received encoded response from the server.
\item \textbf{Total Cost} The addtion of the query and response sizes.

\subsection{Evaluation Results}

\subsubsection{Colouring}

\input{Images/Evaluation/Colouring/Latex_Tables/Encoding_time.tex}
\newpage
\input{Images/Evaluation/Colouring/Latex_Tables/Query_generation_time.tex}
\newpage
\input{Images/Evaluation/Colouring/Latex_Tables/Answer_time.tex}
\newpage
\input{Images/Evaluation/Colouring/Latex_Tables/Query_extraction_time.tex}
\newpage
\input{Images/Evaluation/Colouring/Latex_Tables/Rate.tex}
\newpage
\input{Images/Evaluation/Colouring/Latex_Tables/Query_cost.tex}
\newpage
\input{Images/Evaluation/Colouring/Latex_Tables/Response_cost.tex}
\newpage
\input{Images/Evaluation/Colouring/Latex_Tables/Total_cost.tex}
\newpage

\subsubsection{PBC}

\input{Images/Evaluation/PBC/Latex_Tables/Encoding_time.tex}
\newpage
\input{Images/Evaluation/PBC/Latex_Tables/Query_generation_time.tex}
\newpage
\input{Images/Evaluation/PBC/Latex_Tables/Answer_time.tex}
\newpage
\input{Images/Evaluation/PBC/Latex_Tables/Query_extraction_time.tex}
\newpage
\input{Images/Evaluation/PBC/Latex_Tables/Rate.tex}
\newpage
\input{Images/Evaluation/PBC/Latex_Tables/Query_cost.tex}
\newpage
\input{Images/Evaluation/PBC/Latex_Tables/Response_cost.tex}
\newpage
\input{Images/Evaluation/PBC/Latex_Tables/Total_cost.tex}
\newpage

\subsection{Discussion}

The most extreme database configuration evaluated in the original
paper for Spiral was $2^{20}$ elements where every element size is $256$ bytes\cite{1}.
PIR schemes, such as Spiral, are known to struggle with larger databases, and we found
the required configuration to store anything above $2^{26}$ elements to be infeasible for
most machines. As an example, a database of around $2^{28}$ elements may require upwards
of $700GiB$ of memory.

Database performance across our PBC and colouring datasets are shown to have very similar
performance. This is bacause, for the most part, the database sizes and the number of
hashes to store is almost identical. The only exception to this is when $n$ is above $20$,
where $n$ is the number of leaves in the tree. During such cases, the PBC dataset contains
more hashes than the colouring, which results in a larger database size being used. This
will lead to an increase in database-dependent computations, as well as larger response sizes.

Metrics across $10 \le n \le 19$ for the colouring dataset and $10 \le n \le 18$ for the
PBC dataset are shown to be very similar. This is because Spiral's automatic parameter
selection defined in \cite{1} determines the same database size of $2^{10}$ elements over
these values of $n$. There is a noticeable increase over database-dependant computation across
$n = 2^{20}$ (colouring) and $n = 2^{19}$ (PBC). Both of these values utilises a borderline
configuration with a $p$ value of $4$ and a database size of $2^{11}$ with the next
configurartion using $p = 16$. This "borderline" configuration is likely to be the cause
of this increase in computation time, as the parameter selection may struggle to select
optimal parameters in these edge cases. Note that we did use the unchanged and original
automatic parameter selection method defined in \cite{1}.

The \textit{rate} of our trials appears to diminish significantly as the size of the
required database increases. This pattern is also noted in the original paper\cite{1},
where a decrease in rate corresponds to an increase in database size. A possible
explanation for this observation is that encoding more elements into a single database
entry reduces the overall size of the database. Consequently, a smaller database size
leads to quicker database-dependent computations, especially in operations involving first
dimension multiplication and repeated folding across subsequent dimensions.

Given that we have defined three methodologies to encode hashes across three different
plaintext moduli $p$, we can observe the rate to be of three different corresponding
values: $0.031$, $0.008$ and $0.004$. The first of which is seen on smaller databases,
as a single hash takes up a larger portion of the database record. Likewise, as the value
of $p$ increases, we are able to pack more hashes into a coeffiecient of the ring
polynomial, and thus the rate decreases as more hashes are represented in a record.

The response size provided by the server follows a similar pattern to the rate, with the
sizes gradually increasing as the $p$ value increases. Again, this could be explained by
the need to encode more hashes into a single record in the database. This retrieved
record is what gets sent back, and thus the response size increases as the rate decreases.

Unlike the response size, the query size stays constant throughout all trials. This is
because the procedure to encode the hash index is consistent and irrespective of the database
size used.

The time required to extract the requested hash from the server response is also seen to
slightly increase along with the database size. This is likely due to the fact that the
encoding methodolgies for larger database sizes are more complex, and may therefore
require more time to decode the hash from the server response.
